{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5712b2-bad7-4d6f-8789-7ab2b4259936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7df66fb-d24d-4203-a623-d65c939e348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"course_lead_scoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78607d2-44ed-490b-8cad-e00f83af619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n",
      "(1462, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9ae359-452f-4ee1-8e3c-35e0e5e9582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
      "1457        referral  manufacturing                         1            NaN   \n",
      "1458        referral     technology                         3        65259.0   \n",
      "1459        paid_ads     technology                         1        45688.0   \n",
      "1460        referral            NaN                         5        71016.0   \n",
      "1461  organic_search        finance                         3        92855.0   \n",
      "\n",
      "     employment_status       location  interaction_count  lead_score  \\\n",
      "1457     self_employed  north_america                  4        0.53   \n",
      "1458           student         europe                  2        0.24   \n",
      "1459           student  north_america                  3        0.02   \n",
      "1460     self_employed  north_america                  0        0.25   \n",
      "1461           student  north_america                  3        0.41   \n",
      "\n",
      "      converted  \n",
      "1457          1  \n",
      "1458          1  \n",
      "1459          1  \n",
      "1460          1  \n",
      "1461          1  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88fc721-80db-45b2-aeb3-772afd683f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_summary = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652999ec-c020-442a-8150-aef4236c20c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns with missing values\n",
    "categorical_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "# Numerical columns with missing values\n",
    "numerical_cols = ['annual_income']\n",
    "\n",
    "# Fill missing values\n",
    "df[categorical_cols] = df[categorical_cols].fillna('NA')\n",
    "df[numerical_cols] = df[numerical_cols].fillna(0.0)\n",
    "\n",
    "# Verify\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79fd4fd0-3d80-44c4-af00-dd916c471c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n"
     ]
    }
   ],
   "source": [
    "numerical_cols = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98abb9e0-1944-4e05-be97-898d45cd0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (877, 8), Validation: (292, 8), Test: (293, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('converted', axis=1)\n",
    "y = df['converted']\n",
    "\n",
    "# First, split into train (60%) and temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Then split temp into validation (20%) and test (20%) â†’ each half of temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Check sizes\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3161225-83eb-4e40-af61-f05f3d9f014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'industry': 0.01, 'location': 0.0, 'lead_source': 0.03, 'employment_status': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Categorical features\n",
    "categorical_cols = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "# Encode categorical features\n",
    "X_train_encoded = X_train.copy()\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train_encoded[col])\n",
    "\n",
    "# Calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train_encoded[categorical_cols], y_train, discrete_features=True)\n",
    "\n",
    "# Round scores to 2 decimals and create a dictionary\n",
    "mi_scores_rounded = {col: round(score, 2) for col, score in zip(categorical_cols, mi_scores)}\n",
    "print(mi_scores_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c029d77-5e40-48bf-abf0-8fedd114bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "numerical_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing: one-hot for categorical, passthrough for numerical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Fit on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(round(accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dafcf26-9187-498b-a1f7-b902dcc3a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy differences after removing each feature: {'industry': 0.0, 'employment_status': 0.003424657534246589, 'lead_score': 0.006849315068493067}\n"
     ]
    }
   ],
   "source": [
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "diff_dict = {}\n",
    "\n",
    "for feat in features_to_test:\n",
    "    # Drop feature from X\n",
    "    X_train_temp = X_train.drop(feat, axis=1)\n",
    "    X_val_temp = X_val.drop(feat, axis=1)\n",
    "    \n",
    "    # Update categorical columns\n",
    "    cat_cols_temp = [col for col in categorical_cols if col in X_train_temp.columns]\n",
    "    num_cols_temp = [col for col in X_train_temp.columns if col not in cat_cols_temp]\n",
    "    \n",
    "    preprocessor_temp = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(drop='first'), cat_cols_temp),\n",
    "            ('num', 'passthrough', num_cols_temp)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline_temp = Pipeline([\n",
    "        ('preprocessor', preprocessor_temp),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    pipeline_temp.fit(X_train_temp, y_train)\n",
    "    y_val_pred_temp = pipeline_temp.predict(X_val_temp)\n",
    "    acc_temp = accuracy_score(y_val, y_val_pred_temp)\n",
    "    \n",
    "    diff_dict[feat] = accuracy - acc_temp\n",
    "\n",
    "print(\"Accuracy differences after removing each feature:\", diff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6f3750-73e3-48e9-ba03-eb14726ca70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracies for different C values: {0.01: 0.688, 0.1: 0.682, 1: 0.685, 10: 0.685, 100: 0.685}\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "accuracy_dict = {}\n",
    "\n",
    "for C_val in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C_val, max_iter=1000, random_state=42)\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    accuracy_dict[C_val] = round(accuracy_score(y_val, y_val_pred), 3)\n",
    "\n",
    "print(\"Validation accuracies for different C values:\", accuracy_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
